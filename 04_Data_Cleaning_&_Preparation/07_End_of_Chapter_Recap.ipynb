{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2f44319-95b5-4bbf-9fe7-b351941c4dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228a8122-8938-4324-8f2e-8464478a273b",
   "metadata": {},
   "source": [
    "# RECAP: What we learned in Chapter 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca641ebe-09ab-4526-b7e5-a5fc30c6b7c9",
   "metadata": {},
   "source": [
    "## 1. Handaling missing values:  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0795ea-25eb-460e-80ba-53ee59b49045",
   "metadata": {},
   "source": [
    "1. `.isnull()` -> It returns the entire df but in True/False form (Null/NotNull).\n",
    "2. `.isnull().sum()` -> It returns the number of null values in each column.\n",
    "3. `.isnull().sum().sum()` -> It returns the total number of null values in entire df.  \n",
    "4. `.notnull()`, `.notnull().sum()`, `.notnull().sum().sum()` -> Opposite to `.isnull()`\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d84183f-89d7-41f7-8b28-27b9cabd89fb",
   "metadata": {},
   "source": [
    "1. `.dropna()` -> Drops entire row whhich contains null values. (Returns new df without null values)\n",
    "2. `.dropna(inplace=Ture)` -> To do changes in original df use `inplace=True`.\n",
    "3. `.dropna(how='all')` -> Drops rows which are full empty.\n",
    "4. `.dropna(subset=[...])` -> Drops rows if the specified column have null value.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519cb3b3-27d2-45f8-8101-9c9ec3b846bc",
   "metadata": {},
   "source": [
    "1. `.fillna(0)` -> fill with constant value\n",
    "2. `.fillna(\"XXXXXX\")` -> fill with string  \n",
    "   Use int for int column.  \n",
    "   real world ex  \n",
    "   `df[...].fillna(df[...].mean())` - Fill with mean  \n",
    "   `df[...].fillna(df[...].mediam())` - Fill with median  \n",
    "3. `.ffill()` -> For forward fill\n",
    "4. `.bfill()` -> for backward fill"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf4e53b-ad1e-4b01-8d75-10367c59e618",
   "metadata": {},
   "source": [
    "## 2. Removing duplicates\n",
    "`.drop_duplicates()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6beab2d0-7b2d-428d-8d2f-a353326f94c2",
   "metadata": {},
   "source": [
    "1. `.duplicated()` -> Returns True for which are repeated (Considers full row).\n",
    "2. `.duplicated().sum()` -> Returns total number of duplicate rows.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6760236a-157e-4161-b362-83542d9f1d1a",
   "metadata": {},
   "source": [
    "1. `.drop_duplicates()` -> Remove duplicate rows and returns fresh clean df.\n",
    "2. `.drop_duplicates(subset=[\"City\"])` -> Remove the duplicates only on specified column. So only duplicate cities are removed.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e6dc5a-419a-4ebb-9b65-95394f31b0be",
   "metadata": {},
   "source": [
    "1. `.drop_duplicaes(keep=first)` -> Default\n",
    "2. `.drop_duplicaes(keep=last)` -> Keeps the last occurrence of duplicate values.\n",
    "3. `.drop_duplicaes(keep=False)` -> No keeping remove all data which is duplicate\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe338cca-3326-4360-9930-7dbdd4b8b0f8",
   "metadata": {},
   "source": [
    "1. `.drop_duplicates(inplace=True)` -> Do droping inplace. No return of fresh df.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b0159c-2c4a-40e5-a6ad-ee93c723be59",
   "metadata": {},
   "source": [
    "1. `.drop_duplicates().reset_index(drop=True)` -> Remove duplicates and resets the index. (drop=True)-> Removes the old index column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de2ec5f-6722-4817-b71e-0860ea94c327",
   "metadata": {},
   "source": [
    "## 3. Changing data types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54971121-47ed-4b51-8f70-bcbe7f35a82e",
   "metadata": {},
   "source": [
    "`.dtypes` -> return column wise data types\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e42f260-d55c-47d9-b81a-d57f03d83311",
   "metadata": {},
   "source": [
    "1. `df[\"Age\"].astype(int)` -> The datatype of Age column changed to int  \n",
    "\n",
    "2. For entire df use\n",
    "```\n",
    "df = df.astype({\n",
    "    \"Age\": int,\n",
    "    \"Salary\": float\n",
    "})\n",
    "```\n",
    "3. integer -> int,  \n",
    "   string -> str,  \n",
    "   category -> category,  \n",
    "   boolean -> bool\n",
    "\n",
    "4. Error handling -> Use `pd.to_numeric(df[\"Age\"], error=\"coerce\")`: This makes null for error\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ebec9a-2c22-48a2-aa28-b01c0a52631e",
   "metadata": {},
   "source": [
    "## 4. Renaming Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71039458-4fb2-4408-a592-b1429cacdaad",
   "metadata": {},
   "source": [
    "1. Rename one column -> `df.rename(columns={\"Old\":\"New\"})`\n",
    "2. Rename multiple columns -> \n",
    "```\n",
    "df = df.rename(columns={\n",
    "    \"Old1\": \"New1\",\n",
    "    \"Old2\": \"New2\"\n",
    "})\n",
    "```\n",
    "3. Rename inplace -> `df.rename(columns={\"Old\": \"New\"}, inplace=True)`\n",
    "4. Rename all column at once -> `df.columns = [\"new1\", \"new2\", \"new3\", ....]` (the df contain 5 column then the list also has to contain 5 names, weather you change name or not)\n",
    "5. Auto change column names -> `df.columns = df.columns.str.replace(\" \", \"_\")`: Spaces are replaced by underscore\n",
    "6. `df.columns = df.columns.str.lower()`: All column names to lowercase\n",
    "7. `df.columns = df.columns.str.strip().str.lower().str.replace(\" \", \"_\")` : First strip then lower then replace the spaces with underscore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4869750d-48a3-49b1-a309-07b1a1d1b11f",
   "metadata": {},
   "source": [
    "## 5. String operation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773e09e0-09be-4b12-bd68-52934f8c6241",
   "metadata": {},
   "source": [
    "`df[\"...\"].str.fun()`\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd82949-c2f7-412a-b3d6-2ef59a02f8e9",
   "metadata": {},
   "source": [
    "1. Remove extra spaces  \n",
    "   `.strip()` - Remove leading and trailing spaces  \n",
    "   `.lstrip()` - Remove left side spaces / leading spaces  \n",
    "   `.rstrip()` - Remove right side spaces / trailing spaces\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b20372-9602-4ad7-8ac6-652139c596fe",
   "metadata": {},
   "source": [
    "2. Change letter case  \n",
    "   `.lower()` - all lower case  \n",
    "   `.upper()` - all upper case  \n",
    "   `.title()` - first letter capital rest all\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69b19b8-d394-4928-8689-4f99326b52f4",
   "metadata": {},
   "source": [
    "3. String contains  \n",
    "   `.contains(\"...\")` - used for condition  \n",
    "   ex. `df[df[\"Email\"].str.contains(\"gmail\")]`\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02f0989-b9cf-4ea4-9bb3-f995e935e849",
   "metadata": {},
   "source": [
    "4. Replace str values  \n",
    "   `.replace(\"pune\", \"Pune\", case=False)` - pune/PUNE/PUne... are replaced by Pune\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae9862a-178e-45ce-8968-128764be7d31",
   "metadata": {},
   "source": [
    "5. Extract substring  \n",
    "   `df[\"Gender\"].str[:1]`\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1423d8c-013b-40f8-8158-071791ad5f8c",
   "metadata": {},
   "source": [
    "6. Len of each str  \n",
    "   `df[\"..\"].str.len()`\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12637766-88b9-4611-8977-62b3fab733fc",
   "metadata": {},
   "source": [
    "7. split str  \n",
    "   `df[\"..\"].str.split(\"@\", expand=True)`\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950b1370-d358-4b5c-b923-6b3bf7921e4c",
   "metadata": {},
   "source": [
    "8. Extract particulat column after split  \n",
    "   `df[\"..\"].str.split(\"@\")[0]`  \n",
    "   `df[\"..\"].str.split(\"@\")[1]`\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb8976c-c53f-4621-b8fe-5a355d8e702f",
   "metadata": {},
   "source": [
    "9. Remove symbols and numbers  \n",
    "    `df[\"...\"].str.replace(r\"[^a-zA-Z]\", \"\", regex=True)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4097d1-0807-4648-be6d-cd22e219a06e",
   "metadata": {},
   "source": [
    "## 6. Data and Time conversion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b9b015-b085-4a84-8250-833a2bcced9f",
   "metadata": {},
   "source": [
    "1. Convert date column to DateTime:  \n",
    "   `df[\"...\"] = pd.to_datetime(df[\"...\"])`\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba00acf-3ed7-45c9-95f7-91daf34885ee",
   "metadata": {},
   "source": [
    "2. Extracting Year, Month and Day:  \n",
    "   `df[\"...\"].dt.year`  \n",
    "   `df[\"...\"].dt.month`  \n",
    "   `df[\"...\"].dt.day`\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac0a7c5-e6c7-4dae-8b45-c601de5e7491",
   "metadata": {},
   "source": [
    "3. Extracting day name and month name:  \n",
    "   `df[\"...\"].dt.day_name()`  \n",
    "   `df[\"...\"].dt.day_month()`\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242dc303-9396-4047-b675-f4b46437449c",
   "metadata": {},
   "source": [
    "4. Extract week number and quarter:  \n",
    "   `df[\"...\"].dt.isocalendar().week`  \n",
    "   `df[\"...\"].dt.quarter`\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ba8800-e629-4968-8970-cc49df38e8aa",
   "metadata": {},
   "source": [
    "5. Check min/max date:  \n",
    "   `df[\"...\"].min()` - (The column should be in datetime type)  \n",
    "   `df[\"...\"].max()` - - (The column should be in datetime type)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c070d7-687c-41de-9a75-1967f1400c27",
   "metadata": {},
   "source": [
    "6. Filter by date:  \n",
    "   `df[df[\"...\"] > \"2023-05-10\"]`  \n",
    "   `df[(df[\"...\"] > \"2023-05-10\") & (condition2)]`\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b7b862-3c37-43df-beee-f1bdaff2d3a0",
   "metadata": {},
   "source": [
    "7. Custom date format conversion:  \n",
    "   `pd.to_datetime(df[\"...\"], format=\"%d-%m-%Y\")`\n",
    "   |Format|Meaning|\n",
    "   |-|-|\n",
    "   |%d|Day|\n",
    "   |%m|Month|\n",
    "   |%Y|Year|\n",
    "   |%H|Hour|\n",
    "   |%M|Min|\n",
    "   |%S|Sec|\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a54f1c-9419-4b98-9511-0b4642d963e1",
   "metadata": {},
   "source": [
    "8. Date with time:  \n",
    "   `pd.to_datetime(\"2023-01-20 10:30:00\")`\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e13061-9354-47f5-930c-fb02f3c3befb",
   "metadata": {},
   "source": [
    "9. Handle invalid dates:  \n",
    "    `pd.to_datetime(df[\"...\"], errors=\"coerce\")`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b751d1f3-7f6c-4e12-a407-63f3735da240",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
